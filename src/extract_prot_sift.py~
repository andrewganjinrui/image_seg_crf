# -*- coding: utf-8 -*-
"""
Created on Wed Sep 28 16:07:26 2016

@authors: Santosh, Srikanth
"""


import os
import argparse

from random import shuffle
import numpy as np

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

import pickle
import PIL
import cv2

from multiprocessing import Pool
from collections import defaultdict
from misc.io import chunkify, read_simple_flist


def get_descriptors(ifile):

    img = cv2.imread(ifile)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    sift = cv2.xfeatures2d.SIFT_create()  # raidus parameters here

    kp, des = sift.detectAndCompute(gray, None)

    return kp, des


def main():

    pwd = os.path.dirname(os.path.realpath(__file__)) + "/"

    feat_d = DATA_PRE + "feats/"
    img_dir = DATA_PRE + "PPMImages/"
    lab_d = DATA_PRE + "ImageSets/Main/"
    tmp_d = pwd + "../tmp/"
    etc_d = pwd + "../etc/"

    os.system("mkdir -p " + etc_d)
    os.system("mkdir -p " + tmp_d)

    fid_labels = pickle.load(open(etc_d + "fid_labels.pkl", "rb"))
    labels = read_simple_flist(etc_d + "labels.txt")

    # train_fids = read_simple_flist(lab_d + "train.txt")
    # val_fids = read_simple_flist(lab_d + "val.txt")

    train_flist = sorted(read_simple_flist(lab_d + "train.txt", pre=img_dir,
                                           sfx=".ppm"))
    
    val_flist = sorted(read_simple_flist(lab_d + "val.txt", pre=img_dir, sfx=".ppm"))

    train_fids = []
    all_d = []
    all_k = []
    file_kp_size = []

    st = 0
    for i, tf in enumerate(train_flist):
        
        k, d = get_descriptors(tf)
        
        all_d.append(d)  # append all desc into one list

        # get the file ID (unique key) of the image
        fid = os.path.splitext(os.path.basename(tf))[0]
        train_fids.append(fid)
        
        pickle.dump(all_k, open(feat_d + "kp/kp_" + fid + ".pkl", "wb"))

        # save file ID to no of key points in dict
        file_kp_size.append([st, st + len(k)])
        st += len(k)

        if i > 10:
            break

    all_d = np.concatenate(all_d)
    print('all desc:', all_d.shape)
    #if os.path.exists(feat_d + "sift_train.npy") is False:
    #    np.save(feat_d + "sift_train.npy", all_d)

    with open(feat_d + "train_fids.list", "w") as fpw:
        fpw.write("\n".join(train_fids))

    print(len(file_kp_size), file_kp_size[0:2], file_kp_size[-1])
    file_kp_size = np.concatenate(file_kp_size)
    np.save(feat_d + "kp_index.npy", file_kp_size)
    print(file_kp_size.shape)
        
        
              

if __name__ == "__main__":

    DATA_PRE = "/home/santosh/Downloads/VOCdevkit/VOC2008/"

    parser = argparse.ArgumentParser(description=__doc__)
    args = parser.parse_args()
    main()
